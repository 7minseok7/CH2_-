{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0489f1",
   "metadata": {},
   "source": [
    "# 1. KaggleÏóêÏÑú Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8523c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\wkjeo\\.cache\\kagglehub\\datasets\\ashishkumarak\\netflix-reviews-playstore-daily-updated\\versions\\171\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ashishkumarak/netflix-reviews-playstore-daily-updated\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0a1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Îç∞Ïù¥ÌÑ∞ÏÖã Î∂àÎü¨Ïò§Í∏∞\n",
    "df=pd.read_csv(path + \"\\\\netflix_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad639f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>516f368f-72d8-4abf-9400-e066f2f07b42</td>\n",
       "      <td>Rakesh Patel</td>\n",
       "      <td>Ok</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:54:52</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66d0176c-3838-4ecc-aead-d10588ec6887</td>\n",
       "      <td>Tabassum Kausar</td>\n",
       "      <td>Only problem is that we can't search year wise...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:53:46</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3c8308c-eed0-4cbb-adab-6a076f48a7ab</td>\n",
       "      <td>Hi mu</td>\n",
       "      <td>Good üíú</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-27 13:49:19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6cd609-cfb2-4a7e-b35f-48b289e2984a</td>\n",
       "      <td>Brian C</td>\n",
       "      <td>Can't cast to Chromecast. Unacceptable.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:43:37</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>641edd00-95ec-4214-a03f-60fccafbbb8e</td>\n",
       "      <td>Evans Mgeusa</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:42:29</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  516f368f-72d8-4abf-9400-e066f2f07b42     Rakesh Patel   \n",
       "1  66d0176c-3838-4ecc-aead-d10588ec6887  Tabassum Kausar   \n",
       "2  a3c8308c-eed0-4cbb-adab-6a076f48a7ab            Hi mu   \n",
       "3  6c6cd609-cfb2-4a7e-b35f-48b289e2984a          Brian C   \n",
       "4  641edd00-95ec-4214-a03f-60fccafbbb8e     Evans Mgeusa   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0                                                 Ok      5              0   \n",
       "1  Only problem is that we can't search year wise...      3              0   \n",
       "2                                             Good üíú      5              0   \n",
       "3            Can't cast to Chromecast. Unacceptable.      1              0   \n",
       "4                                            Amazing      5              0   \n",
       "\n",
       "    reviewCreatedVersion                   at             appVersion  \n",
       "0  8.137.0 build 4 50942  2024-10-27 13:54:52  8.137.0 build 4 50942  \n",
       "1  8.137.0 build 4 50942  2024-10-27 13:53:46  8.137.0 build 4 50942  \n",
       "2                    NaN  2024-10-27 13:49:19                    NaN  \n",
       "3  8.137.0 build 4 50942  2024-10-27 13:43:37  8.137.0 build 4 50942  \n",
       "4  8.137.0 build 4 50942  2024-10-27 13:42:29  8.137.0 build 4 50942  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùò ÏÉÅÎã® 5Í∞ú Îç∞Ïù¥ÌÑ∞ Ï∂úÎ†•\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86417cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117640</th>\n",
       "      <td>a760ead9-e7aa-4ed1-a651-5c37c3600dac</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>i really like it! there are so many movies and...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-03 15:06:03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117641</th>\n",
       "      <td>4957f9e7-d7f4-4a52-9764-031cebcac83f</td>\n",
       "      <td>Captain Jeoy</td>\n",
       "      <td>I love Netflix. I always enjoy my time using it.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.34.0 build 4 50250</td>\n",
       "      <td>2022-08-15 16:16:30</td>\n",
       "      <td>8.34.0 build 4 50250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117642</th>\n",
       "      <td>9acf7586-7abf-4b50-8c50-3ede3b2a42c4</td>\n",
       "      <td>Suryansh</td>\n",
       "      <td>Sound quality is very slow of movies</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-17 07:26:58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117643</th>\n",
       "      <td>32870f7f-c461-4256-b602-75244ca60248</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>Rate is very expensive.. bcos we see netflix s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.17.0 build 13 34346</td>\n",
       "      <td>2019-07-21 09:41:42</td>\n",
       "      <td>7.17.0 build 13 34346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117644</th>\n",
       "      <td>dc1352e9-10a8-41ca-ab23-05d045b08e90</td>\n",
       "      <td>suraj soni</td>\n",
       "      <td>this app is awesome for english movies ,series...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-24 11:04:08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reviewId       userName  \\\n",
       "117640  a760ead9-e7aa-4ed1-a651-5c37c3600dac  A Google user   \n",
       "117641  4957f9e7-d7f4-4a52-9764-031cebcac83f   Captain Jeoy   \n",
       "117642  9acf7586-7abf-4b50-8c50-3ede3b2a42c4       Suryansh   \n",
       "117643  32870f7f-c461-4256-b602-75244ca60248  A Google user   \n",
       "117644  dc1352e9-10a8-41ca-ab23-05d045b08e90     suraj soni   \n",
       "\n",
       "                                                  content  score  \\\n",
       "117640  i really like it! there are so many movies and...      5   \n",
       "117641   I love Netflix. I always enjoy my time using it.      5   \n",
       "117642               Sound quality is very slow of movies      1   \n",
       "117643  Rate is very expensive.. bcos we see netflix s...      1   \n",
       "117644  this app is awesome for english movies ,series...      4   \n",
       "\n",
       "        thumbsUpCount   reviewCreatedVersion                   at  \\\n",
       "117640              0                    NaN  2019-08-03 15:06:03   \n",
       "117641              0   8.34.0 build 4 50250  2022-08-15 16:16:30   \n",
       "117642              0                    NaN  2020-08-17 07:26:58   \n",
       "117643              0  7.17.0 build 13 34346  2019-07-21 09:41:42   \n",
       "117644              0                    NaN  2020-05-24 11:04:08   \n",
       "\n",
       "                   appVersion  \n",
       "117640                    NaN  \n",
       "117641   8.34.0 build 4 50250  \n",
       "117642                    NaN  \n",
       "117643  7.17.0 build 13 34346  \n",
       "117644                    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùò ÌïòÎã® 5Í∞ú Îç∞Ïù¥ÌÑ∞ Ï∂úÎ†•\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca12360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (117645, 8)\n",
      "Columns in the dataset: Index(['reviewId', 'userName', 'content', 'score', 'thumbsUpCount',\n",
      "       'reviewCreatedVersion', 'at', 'appVersion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùò columnÍ≥º shape Ï∂úÎ†•\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "print(\"Columns in the dataset:\",df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ef898",
   "metadata": {},
   "source": [
    "# 2. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03734f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>516f368f-72d8-4abf-9400-e066f2f07b42</td>\n",
       "      <td>Rakesh Patel</td>\n",
       "      <td>ok</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:54:52</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66d0176c-3838-4ecc-aead-d10588ec6887</td>\n",
       "      <td>Tabassum Kausar</td>\n",
       "      <td>only problem is that we cant search year wise ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:53:46</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3c8308c-eed0-4cbb-adab-6a076f48a7ab</td>\n",
       "      <td>Hi mu</td>\n",
       "      <td>good</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-27 13:49:19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6cd609-cfb2-4a7e-b35f-48b289e2984a</td>\n",
       "      <td>Brian C</td>\n",
       "      <td>cant cast to chromecast unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:43:37</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>641edd00-95ec-4214-a03f-60fccafbbb8e</td>\n",
       "      <td>Evans Mgeusa</td>\n",
       "      <td>amazing</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "      <td>2024-10-27 13:42:29</td>\n",
       "      <td>8.137.0 build 4 50942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  516f368f-72d8-4abf-9400-e066f2f07b42     Rakesh Patel   \n",
       "1  66d0176c-3838-4ecc-aead-d10588ec6887  Tabassum Kausar   \n",
       "2  a3c8308c-eed0-4cbb-adab-6a076f48a7ab            Hi mu   \n",
       "3  6c6cd609-cfb2-4a7e-b35f-48b289e2984a          Brian C   \n",
       "4  641edd00-95ec-4214-a03f-60fccafbbb8e     Evans Mgeusa   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0                                                 ok      5              0   \n",
       "1  only problem is that we cant search year wise ...      3              0   \n",
       "2                                               good      5              0   \n",
       "3               cant cast to chromecast unacceptable      1              0   \n",
       "4                                            amazing      5              0   \n",
       "\n",
       "    reviewCreatedVersion                   at             appVersion  \n",
       "0  8.137.0 build 4 50942  2024-10-27 13:54:52  8.137.0 build 4 50942  \n",
       "1  8.137.0 build 4 50942  2024-10-27 13:53:46  8.137.0 build 4 50942  \n",
       "2                    NaN  2024-10-27 13:49:19                    NaN  \n",
       "3  8.137.0 build 4 50942  2024-10-27 13:43:37  8.137.0 build 4 50942  \n",
       "4  8.137.0 build 4 50942  2024-10-27 13:42:29  8.137.0 build 4 50942  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):\n",
    "        return \"\"\n",
    "    text = text.lower()  # ÎåÄÎ¨∏ÏûêÎ•º ÏÜåÎ¨∏ÏûêÎ°ú\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Íµ¨ÎëêÏ†ê Ï†úÍ±∞\n",
    "    text = re.sub(r'\\d+', '', text)  # Ïà´Ïûê Ï†úÍ±∞\n",
    "    text = text.strip()  # ÎùÑÏñ¥Ïì∞Í∏∞ Ï†úÏô∏ÌïòÍ≥† Îπà Ïπ∏ Ï†úÍ±∞\n",
    "    return text\n",
    "\n",
    "df.content = df.content.apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74761fd4-8ecd-40eb-a576-68cd937e9dbc",
   "metadata": {},
   "source": [
    "# 3. Feature Î∂ÑÏÑù(EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1db0c82-ae76-4485-98b6-246dc5bdde49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # Í∑∏ÎûòÌîÑÎ•º Í∑∏Î¶¨Í∏∞ ÏúÑÌïú seaborn ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ \n",
    "import matplotlib.pyplot as plt  # Í∑∏ÎûòÌîÑ ÌëúÏãúÎ•º ÏúÑÌïú pyplot ÏûÑÌè¨Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c92fec0a-32c2-48d8-aaeb-b70e9780153a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='score', palette='tab10')\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title('Distribution of Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fc687",
   "metadata": {},
   "source": [
    "# 4. Î¶¨Î∑∞ ÏòàÏ∏° Î™®Îç∏ ÌïôÏäµÏãúÌÇ§Í∏∞(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2f5ea6-778a-432a-9139-3bf37a481726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wkjeo\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "C:\\Users\\wkjeo\\anaconda3\\lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "C:\\Users\\wkjeo\\anaconda3\\lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e952c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, ratings, text_pipeline, label_pipeline):\n",
    "        self.reviews = reviews\n",
    "        self.ratings = ratings\n",
    "        self.text_pipeline = text_pipeline\n",
    "        self.label_pipeline = label_pipeline\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = self.text_pipeline(self.reviews[idx])\n",
    "        rating = self.label_pipeline(self.ratings[idx])\n",
    "        return torch.tensor(review), torch.tensor(rating)\n",
    "    \n",
    "    \n",
    "#Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ïÏùò\n",
    "train_reviews, test_reviews, train_ratings, test_ratings = train_test_split(df.content.to_list(),df.score.to_list(),test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer=get_tokenizer('basic_english')\n",
    "vocab=build_vocab_from_iterator(map(tokenizer, train_reviews), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "max_size = max(len(k.split()) for k in train_reviews + test_reviews)\n",
    "def text_pipeline(text, size=max_size):\n",
    "    k = [vocab[token] for token in tokenizer(text)]\n",
    "    # Î∞∞Ïπò Ï≤òÎ¶¨Î•º ÏúÑÌï¥ Î≤°ÌÑ∞Ïùò Í∏∏Ïù¥Î•º ÎßûÏ∂∞Ï§ÄÎã§.\n",
    "    return k + [0] * (size - len(k))\n",
    "label_pipeline = lambda label: [float(i + 1 == label) for i in range(5)]\n",
    "\n",
    "train_dataset = ReviewDataset(train_reviews, train_ratings, text_pipeline, label_pipeline)\n",
    "test_dataset = ReviewDataset(test_reviews, test_ratings, text_pipeline, label_pipeline)\n",
    "\n",
    "\n",
    "#Îç∞Ïù¥ÌÑ∞Î°úÎçî Ï†ïÏùò\n",
    "BATCH_SIZE=64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca0f0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Î™®Îç∏ Ï†ïÏùò\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.lstm=nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc= nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax=nn.Softmax()\n",
    "    \n",
    "    def forward(self,text):\n",
    "        embedded=self.embedding(text)\n",
    "        output, (hidden, cell)=self.lstm(embedded.unsqueeze(0))\n",
    "        output=self.fc(output[-1])\n",
    "        return self.softmax(output)\n",
    "    \n",
    "#ÌïòÏù¥Ìçº Ìå®Îü¨ÎØ∏ÌÑ∞ Ï†ïÏùò\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBED_DIM = 96\n",
    "HIDDEN_DIM = 192\n",
    "OUTPUT_DIM = 5\n",
    "\n",
    "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348c79d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wkjeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 100] loss: 1.498\n",
      "[Epoch 1, Batch 200] loss: 1.492\n",
      "[Epoch 1, Batch 300] loss: 1.458\n",
      "[Epoch 1, Batch 400] loss: 1.417\n",
      "[Epoch 1, Batch 500] loss: 1.385\n",
      "[Epoch 1, Batch 600] loss: 1.356\n",
      "[Epoch 1, Batch 700] loss: 1.341\n",
      "[Epoch 1, Batch 800] loss: 1.328\n",
      "[Epoch 1, Batch 900] loss: 1.321\n",
      "[Epoch 1, Batch 1000] loss: 1.314\n",
      "[Epoch 1, Batch 1100] loss: 1.320\n",
      "[Epoch 1, Batch 1200] loss: 1.321\n",
      "[Epoch 1, Batch 1300] loss: 1.308\n",
      "[Epoch 1, Batch 1400] loss: 1.314\n",
      "[Epoch 2, Batch 100] loss: 1.295\n",
      "[Epoch 2, Batch 200] loss: 1.295\n",
      "[Epoch 2, Batch 300] loss: 1.301\n",
      "[Epoch 2, Batch 400] loss: 1.296\n",
      "[Epoch 2, Batch 500] loss: 1.293\n",
      "[Epoch 2, Batch 600] loss: 1.291\n",
      "[Epoch 2, Batch 700] loss: 1.299\n",
      "[Epoch 2, Batch 800] loss: 1.301\n",
      "[Epoch 2, Batch 900] loss: 1.300\n",
      "[Epoch 2, Batch 1000] loss: 1.299\n",
      "[Epoch 2, Batch 1100] loss: 1.288\n",
      "[Epoch 2, Batch 1200] loss: 1.282\n",
      "[Epoch 2, Batch 1300] loss: 1.294\n",
      "[Epoch 2, Batch 1400] loss: 1.289\n",
      "[Epoch 3, Batch 100] loss: 1.281\n",
      "[Epoch 3, Batch 200] loss: 1.287\n",
      "[Epoch 3, Batch 300] loss: 1.284\n",
      "[Epoch 3, Batch 400] loss: 1.283\n",
      "[Epoch 3, Batch 500] loss: 1.288\n",
      "[Epoch 3, Batch 600] loss: 1.287\n",
      "[Epoch 3, Batch 700] loss: 1.283\n",
      "[Epoch 3, Batch 800] loss: 1.284\n",
      "[Epoch 3, Batch 900] loss: 1.277\n",
      "[Epoch 3, Batch 1000] loss: 1.281\n",
      "[Epoch 3, Batch 1100] loss: 1.286\n",
      "[Epoch 3, Batch 1200] loss: 1.287\n",
      "[Epoch 3, Batch 1300] loss: 1.283\n",
      "[Epoch 3, Batch 1400] loss: 1.288\n",
      "[Epoch 4, Batch 100] loss: 1.275\n",
      "[Epoch 4, Batch 200] loss: 1.291\n",
      "[Epoch 4, Batch 300] loss: 1.282\n",
      "[Epoch 4, Batch 400] loss: 1.280\n",
      "[Epoch 4, Batch 500] loss: 1.285\n",
      "[Epoch 4, Batch 600] loss: 1.278\n",
      "[Epoch 4, Batch 700] loss: 1.284\n",
      "[Epoch 4, Batch 800] loss: 1.280\n",
      "[Epoch 4, Batch 900] loss: 1.270\n",
      "[Epoch 4, Batch 1000] loss: 1.282\n",
      "[Epoch 4, Batch 1100] loss: 1.274\n",
      "[Epoch 4, Batch 1200] loss: 1.281\n",
      "[Epoch 4, Batch 1300] loss: 1.279\n",
      "[Epoch 4, Batch 1400] loss: 1.275\n",
      "[Epoch 5, Batch 100] loss: 1.284\n",
      "[Epoch 5, Batch 200] loss: 1.277\n",
      "[Epoch 5, Batch 300] loss: 1.276\n",
      "[Epoch 5, Batch 400] loss: 1.289\n",
      "[Epoch 5, Batch 500] loss: 1.274\n",
      "[Epoch 5, Batch 600] loss: 1.271\n",
      "[Epoch 5, Batch 700] loss: 1.272\n",
      "[Epoch 5, Batch 800] loss: 1.274\n",
      "[Epoch 5, Batch 900] loss: 1.271\n",
      "[Epoch 5, Batch 1000] loss: 1.283\n",
      "[Epoch 5, Batch 1100] loss: 1.271\n",
      "[Epoch 5, Batch 1200] loss: 1.272\n",
      "[Epoch 5, Batch 1300] loss: 1.271\n",
      "[Epoch 5, Batch 1400] loss: 1.276\n",
      "[Epoch 6, Batch 100] loss: 1.268\n",
      "[Epoch 6, Batch 200] loss: 1.269\n",
      "[Epoch 6, Batch 300] loss: 1.275\n",
      "[Epoch 6, Batch 400] loss: 1.270\n",
      "[Epoch 6, Batch 500] loss: 1.275\n",
      "[Epoch 6, Batch 600] loss: 1.275\n",
      "[Epoch 6, Batch 700] loss: 1.277\n",
      "[Epoch 6, Batch 800] loss: 1.274\n",
      "[Epoch 6, Batch 900] loss: 1.274\n",
      "[Epoch 6, Batch 1000] loss: 1.283\n",
      "[Epoch 6, Batch 1100] loss: 1.271\n",
      "[Epoch 6, Batch 1200] loss: 1.274\n",
      "[Epoch 6, Batch 1300] loss: 1.278\n",
      "[Epoch 6, Batch 1400] loss: 1.270\n",
      "[Epoch 7, Batch 100] loss: 1.268\n",
      "[Epoch 7, Batch 200] loss: 1.269\n",
      "[Epoch 7, Batch 300] loss: 1.273\n",
      "[Epoch 7, Batch 400] loss: 1.273\n",
      "[Epoch 7, Batch 500] loss: 1.272\n",
      "[Epoch 7, Batch 600] loss: 1.271\n",
      "[Epoch 7, Batch 700] loss: 1.267\n",
      "[Epoch 7, Batch 800] loss: 1.266\n",
      "[Epoch 7, Batch 900] loss: 1.273\n",
      "[Epoch 7, Batch 1000] loss: 1.269\n",
      "[Epoch 7, Batch 1100] loss: 1.271\n",
      "[Epoch 7, Batch 1200] loss: 1.275\n",
      "[Epoch 7, Batch 1300] loss: 1.276\n",
      "[Epoch 7, Batch 1400] loss: 1.278\n",
      "[Epoch 8, Batch 100] loss: 1.268\n",
      "[Epoch 8, Batch 200] loss: 1.279\n",
      "[Epoch 8, Batch 300] loss: 1.279\n",
      "[Epoch 8, Batch 400] loss: 1.280\n",
      "[Epoch 8, Batch 500] loss: 1.266\n",
      "[Epoch 8, Batch 600] loss: 1.277\n",
      "[Epoch 8, Batch 700] loss: 1.267\n",
      "[Epoch 8, Batch 800] loss: 1.271\n",
      "[Epoch 8, Batch 900] loss: 1.268\n",
      "[Epoch 8, Batch 1000] loss: 1.265\n",
      "[Epoch 8, Batch 1100] loss: 1.255\n",
      "[Epoch 8, Batch 1200] loss: 1.270\n",
      "[Epoch 8, Batch 1300] loss: 1.269\n",
      "[Epoch 8, Batch 1400] loss: 1.268\n",
      "[Epoch 9, Batch 100] loss: 1.267\n",
      "[Epoch 9, Batch 200] loss: 1.272\n",
      "[Epoch 9, Batch 300] loss: 1.272\n",
      "[Epoch 9, Batch 400] loss: 1.274\n",
      "[Epoch 9, Batch 500] loss: 1.270\n",
      "[Epoch 9, Batch 600] loss: 1.277\n",
      "[Epoch 9, Batch 700] loss: 1.269\n",
      "[Epoch 9, Batch 800] loss: 1.264\n",
      "[Epoch 9, Batch 900] loss: 1.259\n",
      "[Epoch 9, Batch 1000] loss: 1.267\n",
      "[Epoch 9, Batch 1100] loss: 1.268\n",
      "[Epoch 9, Batch 1200] loss: 1.270\n",
      "[Epoch 9, Batch 1300] loss: 1.268\n",
      "[Epoch 9, Batch 1400] loss: 1.262\n",
      "[Epoch 10, Batch 100] loss: 1.277\n",
      "[Epoch 10, Batch 200] loss: 1.264\n",
      "[Epoch 10, Batch 300] loss: 1.261\n",
      "[Epoch 10, Batch 400] loss: 1.259\n",
      "[Epoch 10, Batch 500] loss: 1.268\n",
      "[Epoch 10, Batch 600] loss: 1.266\n",
      "[Epoch 10, Batch 700] loss: 1.278\n",
      "[Epoch 10, Batch 800] loss: 1.270\n",
      "[Epoch 10, Batch 900] loss: 1.264\n",
      "[Epoch 10, Batch 1000] loss: 1.278\n",
      "[Epoch 10, Batch 1100] loss: 1.272\n",
      "[Epoch 10, Batch 1200] loss: 1.269\n",
      "[Epoch 10, Batch 1300] loss: 1.275\n",
      "[Epoch 10, Batch 1400] loss: 1.258\n",
      "[Epoch 11, Batch 100] loss: 1.270\n",
      "[Epoch 11, Batch 200] loss: 1.263\n",
      "[Epoch 11, Batch 300] loss: 1.271\n",
      "[Epoch 11, Batch 400] loss: 1.266\n",
      "[Epoch 11, Batch 500] loss: 1.274\n",
      "[Epoch 11, Batch 600] loss: 1.267\n",
      "[Epoch 11, Batch 700] loss: 1.263\n",
      "[Epoch 11, Batch 800] loss: 1.268\n",
      "[Epoch 11, Batch 900] loss: 1.270\n",
      "[Epoch 11, Batch 1000] loss: 1.264\n",
      "[Epoch 11, Batch 1100] loss: 1.259\n",
      "[Epoch 11, Batch 1200] loss: 1.263\n",
      "[Epoch 11, Batch 1300] loss: 1.275\n",
      "[Epoch 11, Batch 1400] loss: 1.266\n",
      "[Epoch 12, Batch 100] loss: 1.272\n",
      "[Epoch 12, Batch 200] loss: 1.274\n",
      "[Epoch 12, Batch 300] loss: 1.274\n",
      "[Epoch 12, Batch 400] loss: 1.260\n",
      "[Epoch 12, Batch 500] loss: 1.271\n",
      "[Epoch 12, Batch 600] loss: 1.273\n",
      "[Epoch 12, Batch 700] loss: 1.257\n",
      "[Epoch 12, Batch 800] loss: 1.273\n",
      "[Epoch 12, Batch 900] loss: 1.268\n",
      "[Epoch 12, Batch 1000] loss: 1.262\n",
      "[Epoch 12, Batch 1100] loss: 1.267\n",
      "[Epoch 12, Batch 1200] loss: 1.258\n",
      "[Epoch 12, Batch 1300] loss: 1.258\n",
      "[Epoch 12, Batch 1400] loss: 1.263\n",
      "[Epoch 13, Batch 100] loss: 1.259\n",
      "[Epoch 13, Batch 200] loss: 1.261\n",
      "[Epoch 13, Batch 300] loss: 1.257\n",
      "[Epoch 13, Batch 400] loss: 1.258\n",
      "[Epoch 13, Batch 500] loss: 1.271\n",
      "[Epoch 13, Batch 600] loss: 1.274\n",
      "[Epoch 13, Batch 700] loss: 1.271\n",
      "[Epoch 13, Batch 800] loss: 1.269\n",
      "[Epoch 13, Batch 900] loss: 1.265\n",
      "[Epoch 13, Batch 1000] loss: 1.265\n",
      "[Epoch 13, Batch 1100] loss: 1.266\n",
      "[Epoch 13, Batch 1200] loss: 1.272\n",
      "[Epoch 13, Batch 1300] loss: 1.260\n",
      "[Epoch 13, Batch 1400] loss: 1.271\n",
      "[Epoch 14, Batch 100] loss: 1.267\n",
      "[Epoch 14, Batch 200] loss: 1.261\n",
      "[Epoch 14, Batch 300] loss: 1.268\n",
      "[Epoch 14, Batch 400] loss: 1.274\n",
      "[Epoch 14, Batch 500] loss: 1.255\n",
      "[Epoch 14, Batch 600] loss: 1.270\n",
      "[Epoch 14, Batch 700] loss: 1.265\n",
      "[Epoch 14, Batch 800] loss: 1.277\n",
      "[Epoch 14, Batch 900] loss: 1.259\n",
      "[Epoch 14, Batch 1000] loss: 1.262\n",
      "[Epoch 14, Batch 1100] loss: 1.262\n",
      "[Epoch 14, Batch 1200] loss: 1.255\n",
      "[Epoch 14, Batch 1300] loss: 1.271\n",
      "[Epoch 14, Batch 1400] loss: 1.263\n",
      "[Epoch 15, Batch 100] loss: 1.264\n",
      "[Epoch 15, Batch 200] loss: 1.268\n",
      "[Epoch 15, Batch 300] loss: 1.252\n",
      "[Epoch 15, Batch 400] loss: 1.259\n",
      "[Epoch 15, Batch 500] loss: 1.268\n",
      "[Epoch 15, Batch 600] loss: 1.258\n",
      "[Epoch 15, Batch 700] loss: 1.269\n",
      "[Epoch 15, Batch 800] loss: 1.264\n",
      "[Epoch 15, Batch 900] loss: 1.275\n",
      "[Epoch 15, Batch 1000] loss: 1.270\n",
      "[Epoch 15, Batch 1100] loss: 1.264\n",
      "[Epoch 15, Batch 1200] loss: 1.263\n",
      "[Epoch 15, Batch 1300] loss: 1.264\n",
      "[Epoch 15, Batch 1400] loss: 1.268\n",
      "[Epoch 16, Batch 100] loss: 1.265\n",
      "[Epoch 16, Batch 200] loss: 1.262\n",
      "[Epoch 16, Batch 300] loss: 1.260\n",
      "[Epoch 16, Batch 400] loss: 1.266\n",
      "[Epoch 16, Batch 500] loss: 1.268\n",
      "[Epoch 16, Batch 600] loss: 1.267\n",
      "[Epoch 16, Batch 700] loss: 1.254\n",
      "[Epoch 16, Batch 800] loss: 1.267\n",
      "[Epoch 16, Batch 900] loss: 1.260\n",
      "[Epoch 16, Batch 1000] loss: 1.262\n",
      "[Epoch 16, Batch 1100] loss: 1.271\n",
      "[Epoch 16, Batch 1200] loss: 1.263\n",
      "[Epoch 16, Batch 1300] loss: 1.266\n",
      "[Epoch 16, Batch 1400] loss: 1.261\n",
      "[Epoch 17, Batch 100] loss: 1.259\n",
      "[Epoch 17, Batch 200] loss: 1.257\n",
      "[Epoch 17, Batch 300] loss: 1.253\n",
      "[Epoch 17, Batch 400] loss: 1.259\n",
      "[Epoch 17, Batch 500] loss: 1.263\n",
      "[Epoch 17, Batch 600] loss: 1.265\n",
      "[Epoch 17, Batch 700] loss: 1.264\n",
      "[Epoch 17, Batch 800] loss: 1.267\n",
      "[Epoch 17, Batch 900] loss: 1.265\n",
      "[Epoch 17, Batch 1000] loss: 1.265\n",
      "[Epoch 17, Batch 1100] loss: 1.270\n",
      "[Epoch 17, Batch 1200] loss: 1.266\n",
      "[Epoch 17, Batch 1300] loss: 1.266\n",
      "[Epoch 17, Batch 1400] loss: 1.261\n",
      "[Epoch 18, Batch 100] loss: 1.274\n",
      "[Epoch 18, Batch 200] loss: 1.265\n",
      "[Epoch 18, Batch 300] loss: 1.267\n",
      "[Epoch 18, Batch 400] loss: 1.265\n",
      "[Epoch 18, Batch 500] loss: 1.273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18, Batch 600] loss: 1.258\n",
      "[Epoch 18, Batch 700] loss: 1.256\n",
      "[Epoch 18, Batch 800] loss: 1.253\n",
      "[Epoch 18, Batch 900] loss: 1.264\n",
      "[Epoch 18, Batch 1000] loss: 1.268\n",
      "[Epoch 18, Batch 1100] loss: 1.267\n",
      "[Epoch 18, Batch 1200] loss: 1.260\n",
      "[Epoch 18, Batch 1300] loss: 1.257\n",
      "[Epoch 18, Batch 1400] loss: 1.252\n",
      "[Epoch 19, Batch 100] loss: 1.256\n",
      "[Epoch 19, Batch 200] loss: 1.260\n",
      "[Epoch 19, Batch 300] loss: 1.256\n",
      "[Epoch 19, Batch 400] loss: 1.258\n",
      "[Epoch 19, Batch 500] loss: 1.262\n",
      "[Epoch 19, Batch 600] loss: 1.266\n",
      "[Epoch 19, Batch 700] loss: 1.257\n",
      "[Epoch 19, Batch 800] loss: 1.264\n",
      "[Epoch 19, Batch 900] loss: 1.271\n",
      "[Epoch 19, Batch 1000] loss: 1.271\n",
      "[Epoch 19, Batch 1100] loss: 1.260\n",
      "[Epoch 19, Batch 1200] loss: 1.260\n",
      "[Epoch 19, Batch 1300] loss: 1.267\n",
      "[Epoch 19, Batch 1400] loss: 1.269\n",
      "[Epoch 20, Batch 100] loss: 1.269\n",
      "[Epoch 20, Batch 200] loss: 1.258\n",
      "[Epoch 20, Batch 300] loss: 1.263\n",
      "[Epoch 20, Batch 400] loss: 1.257\n",
      "[Epoch 20, Batch 500] loss: 1.263\n",
      "[Epoch 20, Batch 600] loss: 1.267\n",
      "[Epoch 20, Batch 700] loss: 1.255\n",
      "[Epoch 20, Batch 800] loss: 1.268\n",
      "[Epoch 20, Batch 900] loss: 1.259\n",
      "[Epoch 20, Batch 1000] loss: 1.265\n",
      "[Epoch 20, Batch 1100] loss: 1.263\n",
      "[Epoch 20, Batch 1200] loss: 1.263\n",
      "[Epoch 20, Batch 1300] loss: 1.261\n",
      "[Epoch 20, Batch 1400] loss: 1.256\n",
      "[Epoch 21, Batch 100] loss: 1.263\n",
      "[Epoch 21, Batch 200] loss: 1.258\n",
      "[Epoch 21, Batch 300] loss: 1.264\n",
      "[Epoch 21, Batch 400] loss: 1.258\n",
      "[Epoch 21, Batch 500] loss: 1.254\n",
      "[Epoch 21, Batch 600] loss: 1.254\n",
      "[Epoch 21, Batch 700] loss: 1.257\n",
      "[Epoch 21, Batch 800] loss: 1.268\n",
      "[Epoch 21, Batch 900] loss: 1.268\n",
      "[Epoch 21, Batch 1000] loss: 1.265\n",
      "[Epoch 21, Batch 1100] loss: 1.262\n",
      "[Epoch 21, Batch 1200] loss: 1.270\n",
      "[Epoch 21, Batch 1300] loss: 1.267\n",
      "[Epoch 21, Batch 1400] loss: 1.259\n",
      "[Epoch 22, Batch 100] loss: 1.265\n",
      "[Epoch 22, Batch 200] loss: 1.265\n",
      "[Epoch 22, Batch 300] loss: 1.260\n",
      "[Epoch 22, Batch 400] loss: 1.264\n",
      "[Epoch 22, Batch 500] loss: 1.258\n",
      "[Epoch 22, Batch 600] loss: 1.257\n",
      "[Epoch 22, Batch 700] loss: 1.273\n",
      "[Epoch 22, Batch 800] loss: 1.266\n",
      "[Epoch 22, Batch 900] loss: 1.249\n",
      "[Epoch 22, Batch 1000] loss: 1.257\n",
      "[Epoch 22, Batch 1100] loss: 1.264\n",
      "[Epoch 22, Batch 1200] loss: 1.262\n",
      "[Epoch 22, Batch 1300] loss: 1.258\n",
      "[Epoch 22, Batch 1400] loss: 1.263\n",
      "[Epoch 23, Batch 100] loss: 1.273\n",
      "[Epoch 23, Batch 200] loss: 1.269\n",
      "[Epoch 23, Batch 300] loss: 1.257\n",
      "[Epoch 23, Batch 400] loss: 1.270\n",
      "[Epoch 23, Batch 500] loss: 1.255\n",
      "[Epoch 23, Batch 600] loss: 1.255\n",
      "[Epoch 23, Batch 700] loss: 1.267\n",
      "[Epoch 23, Batch 800] loss: 1.252\n",
      "[Epoch 23, Batch 900] loss: 1.260\n",
      "[Epoch 23, Batch 1000] loss: 1.251\n",
      "[Epoch 23, Batch 1100] loss: 1.249\n",
      "[Epoch 23, Batch 1200] loss: 1.261\n",
      "[Epoch 23, Batch 1300] loss: 1.260\n",
      "[Epoch 23, Batch 1400] loss: 1.267\n",
      "[Epoch 24, Batch 100] loss: 1.253\n",
      "[Epoch 24, Batch 200] loss: 1.266\n",
      "[Epoch 24, Batch 300] loss: 1.258\n",
      "[Epoch 24, Batch 400] loss: 1.262\n",
      "[Epoch 24, Batch 500] loss: 1.253\n",
      "[Epoch 24, Batch 600] loss: 1.254\n",
      "[Epoch 24, Batch 700] loss: 1.255\n",
      "[Epoch 24, Batch 800] loss: 1.255\n",
      "[Epoch 24, Batch 900] loss: 1.263\n",
      "[Epoch 24, Batch 1000] loss: 1.261\n",
      "[Epoch 24, Batch 1100] loss: 1.260\n",
      "[Epoch 24, Batch 1200] loss: 1.264\n",
      "[Epoch 24, Batch 1300] loss: 1.254\n",
      "[Epoch 24, Batch 1400] loss: 1.277\n",
      "[Epoch 25, Batch 100] loss: 1.269\n",
      "[Epoch 25, Batch 200] loss: 1.254\n",
      "[Epoch 25, Batch 300] loss: 1.268\n",
      "[Epoch 25, Batch 400] loss: 1.259\n",
      "[Epoch 25, Batch 500] loss: 1.266\n",
      "[Epoch 25, Batch 600] loss: 1.250\n",
      "[Epoch 25, Batch 700] loss: 1.260\n",
      "[Epoch 25, Batch 800] loss: 1.270\n",
      "[Epoch 25, Batch 900] loss: 1.251\n",
      "[Epoch 25, Batch 1000] loss: 1.266\n",
      "[Epoch 25, Batch 1100] loss: 1.260\n",
      "[Epoch 25, Batch 1200] loss: 1.257\n",
      "[Epoch 25, Batch 1300] loss: 1.260\n",
      "[Epoch 25, Batch 1400] loss: 1.248\n",
      "[Epoch 26, Batch 100] loss: 1.259\n",
      "[Epoch 26, Batch 200] loss: 1.258\n",
      "[Epoch 26, Batch 300] loss: 1.264\n",
      "[Epoch 26, Batch 400] loss: 1.259\n",
      "[Epoch 26, Batch 500] loss: 1.257\n",
      "[Epoch 26, Batch 600] loss: 1.263\n",
      "[Epoch 26, Batch 700] loss: 1.256\n",
      "[Epoch 26, Batch 800] loss: 1.251\n",
      "[Epoch 26, Batch 900] loss: 1.264\n",
      "[Epoch 26, Batch 1000] loss: 1.271\n",
      "[Epoch 26, Batch 1100] loss: 1.253\n",
      "[Epoch 26, Batch 1200] loss: 1.271\n",
      "[Epoch 26, Batch 1300] loss: 1.248\n",
      "[Epoch 26, Batch 1400] loss: 1.258\n",
      "[Epoch 27, Batch 100] loss: 1.269\n",
      "[Epoch 27, Batch 200] loss: 1.253\n",
      "[Epoch 27, Batch 300] loss: 1.255\n",
      "[Epoch 27, Batch 400] loss: 1.259\n",
      "[Epoch 27, Batch 500] loss: 1.259\n",
      "[Epoch 27, Batch 600] loss: 1.259\n",
      "[Epoch 27, Batch 700] loss: 1.258\n",
      "[Epoch 27, Batch 800] loss: 1.249\n",
      "[Epoch 27, Batch 900] loss: 1.248\n",
      "[Epoch 27, Batch 1000] loss: 1.257\n",
      "[Epoch 27, Batch 1100] loss: 1.261\n",
      "[Epoch 27, Batch 1200] loss: 1.271\n",
      "[Epoch 27, Batch 1300] loss: 1.268\n",
      "[Epoch 27, Batch 1400] loss: 1.263\n",
      "[Epoch 28, Batch 100] loss: 1.252\n",
      "[Epoch 28, Batch 200] loss: 1.259\n",
      "[Epoch 28, Batch 300] loss: 1.263\n",
      "[Epoch 28, Batch 400] loss: 1.259\n",
      "[Epoch 28, Batch 500] loss: 1.264\n",
      "[Epoch 28, Batch 600] loss: 1.268\n",
      "[Epoch 28, Batch 700] loss: 1.261\n",
      "[Epoch 28, Batch 800] loss: 1.265\n",
      "[Epoch 28, Batch 900] loss: 1.250\n",
      "[Epoch 28, Batch 1000] loss: 1.255\n",
      "[Epoch 28, Batch 1100] loss: 1.257\n",
      "[Epoch 28, Batch 1200] loss: 1.259\n",
      "[Epoch 28, Batch 1300] loss: 1.258\n",
      "[Epoch 28, Batch 1400] loss: 1.254\n",
      "[Epoch 29, Batch 100] loss: 1.255\n",
      "[Epoch 29, Batch 200] loss: 1.254\n",
      "[Epoch 29, Batch 300] loss: 1.262\n",
      "[Epoch 29, Batch 400] loss: 1.264\n",
      "[Epoch 29, Batch 500] loss: 1.264\n",
      "[Epoch 29, Batch 600] loss: 1.258\n",
      "[Epoch 29, Batch 700] loss: 1.253\n",
      "[Epoch 29, Batch 800] loss: 1.259\n",
      "[Epoch 29, Batch 900] loss: 1.264\n",
      "[Epoch 29, Batch 1000] loss: 1.260\n",
      "[Epoch 29, Batch 1100] loss: 1.252\n",
      "[Epoch 29, Batch 1200] loss: 1.258\n",
      "[Epoch 29, Batch 1300] loss: 1.246\n",
      "[Epoch 29, Batch 1400] loss: 1.266\n",
      "[Epoch 30, Batch 100] loss: 1.256\n",
      "[Epoch 30, Batch 200] loss: 1.255\n",
      "[Epoch 30, Batch 300] loss: 1.262\n",
      "[Epoch 30, Batch 400] loss: 1.260\n",
      "[Epoch 30, Batch 500] loss: 1.261\n",
      "[Epoch 30, Batch 600] loss: 1.254\n",
      "[Epoch 30, Batch 700] loss: 1.250\n",
      "[Epoch 30, Batch 800] loss: 1.256\n",
      "[Epoch 30, Batch 900] loss: 1.258\n",
      "[Epoch 30, Batch 1000] loss: 1.257\n",
      "[Epoch 30, Batch 1100] loss: 1.256\n",
      "[Epoch 30, Batch 1200] loss: 1.264\n",
      "[Epoch 30, Batch 1300] loss: 1.260\n",
      "[Epoch 30, Batch 1400] loss: 1.262\n",
      "[Epoch 31, Batch 100] loss: 1.264\n",
      "[Epoch 31, Batch 200] loss: 1.270\n",
      "[Epoch 31, Batch 300] loss: 1.248\n",
      "[Epoch 31, Batch 400] loss: 1.253\n",
      "[Epoch 31, Batch 500] loss: 1.263\n",
      "[Epoch 31, Batch 600] loss: 1.254\n",
      "[Epoch 31, Batch 700] loss: 1.247\n",
      "[Epoch 31, Batch 800] loss: 1.267\n",
      "[Epoch 31, Batch 900] loss: 1.254\n",
      "[Epoch 31, Batch 1000] loss: 1.253\n",
      "[Epoch 31, Batch 1100] loss: 1.259\n",
      "[Epoch 31, Batch 1200] loss: 1.268\n",
      "[Epoch 31, Batch 1300] loss: 1.263\n",
      "[Epoch 31, Batch 1400] loss: 1.249\n",
      "[Epoch 32, Batch 100] loss: 1.257\n",
      "[Epoch 32, Batch 200] loss: 1.256\n",
      "[Epoch 32, Batch 300] loss: 1.254\n",
      "[Epoch 32, Batch 400] loss: 1.263\n",
      "[Epoch 32, Batch 500] loss: 1.259\n",
      "[Epoch 32, Batch 600] loss: 1.249\n",
      "[Epoch 32, Batch 700] loss: 1.255\n",
      "[Epoch 32, Batch 800] loss: 1.262\n",
      "[Epoch 32, Batch 900] loss: 1.253\n",
      "[Epoch 32, Batch 1000] loss: 1.255\n",
      "[Epoch 32, Batch 1100] loss: 1.251\n",
      "[Epoch 32, Batch 1200] loss: 1.264\n",
      "[Epoch 32, Batch 1300] loss: 1.270\n",
      "[Epoch 32, Batch 1400] loss: 1.255\n",
      "[Epoch 33, Batch 100] loss: 1.253\n",
      "[Epoch 33, Batch 200] loss: 1.254\n",
      "[Epoch 33, Batch 300] loss: 1.261\n",
      "[Epoch 33, Batch 400] loss: 1.256\n",
      "[Epoch 33, Batch 500] loss: 1.250\n",
      "[Epoch 33, Batch 600] loss: 1.265\n",
      "[Epoch 33, Batch 700] loss: 1.262\n",
      "[Epoch 33, Batch 800] loss: 1.264\n",
      "[Epoch 33, Batch 900] loss: 1.251\n",
      "[Epoch 33, Batch 1000] loss: 1.254\n",
      "[Epoch 33, Batch 1100] loss: 1.245\n",
      "[Epoch 33, Batch 1200] loss: 1.266\n",
      "[Epoch 33, Batch 1300] loss: 1.269\n",
      "[Epoch 33, Batch 1400] loss: 1.253\n",
      "[Epoch 34, Batch 100] loss: 1.253\n",
      "[Epoch 34, Batch 200] loss: 1.257\n",
      "[Epoch 34, Batch 300] loss: 1.246\n",
      "[Epoch 34, Batch 400] loss: 1.257\n",
      "[Epoch 34, Batch 500] loss: 1.255\n",
      "[Epoch 34, Batch 600] loss: 1.261\n",
      "[Epoch 34, Batch 700] loss: 1.255\n",
      "[Epoch 34, Batch 800] loss: 1.255\n",
      "[Epoch 34, Batch 900] loss: 1.273\n",
      "[Epoch 34, Batch 1000] loss: 1.256\n",
      "[Epoch 34, Batch 1100] loss: 1.259\n",
      "[Epoch 34, Batch 1200] loss: 1.255\n",
      "[Epoch 34, Batch 1300] loss: 1.258\n",
      "[Epoch 34, Batch 1400] loss: 1.265\n",
      "[Epoch 35, Batch 100] loss: 1.258\n",
      "[Epoch 35, Batch 200] loss: 1.268\n",
      "[Epoch 35, Batch 300] loss: 1.251\n",
      "[Epoch 35, Batch 400] loss: 1.248\n",
      "[Epoch 35, Batch 500] loss: 1.256\n",
      "[Epoch 35, Batch 600] loss: 1.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35, Batch 700] loss: 1.254\n",
      "[Epoch 35, Batch 800] loss: 1.262\n",
      "[Epoch 35, Batch 900] loss: 1.264\n",
      "[Epoch 35, Batch 1000] loss: 1.254\n",
      "[Epoch 35, Batch 1100] loss: 1.260\n",
      "[Epoch 35, Batch 1200] loss: 1.258\n",
      "[Epoch 35, Batch 1300] loss: 1.262\n",
      "[Epoch 35, Batch 1400] loss: 1.250\n",
      "[Epoch 36, Batch 100] loss: 1.251\n",
      "[Epoch 36, Batch 200] loss: 1.257\n",
      "[Epoch 36, Batch 300] loss: 1.252\n",
      "[Epoch 36, Batch 400] loss: 1.249\n",
      "[Epoch 36, Batch 500] loss: 1.259\n",
      "[Epoch 36, Batch 600] loss: 1.263\n",
      "[Epoch 36, Batch 700] loss: 1.254\n",
      "[Epoch 36, Batch 800] loss: 1.257\n",
      "[Epoch 36, Batch 900] loss: 1.250\n",
      "[Epoch 36, Batch 1000] loss: 1.274\n",
      "[Epoch 36, Batch 1100] loss: 1.261\n",
      "[Epoch 36, Batch 1200] loss: 1.241\n",
      "[Epoch 36, Batch 1300] loss: 1.266\n",
      "[Epoch 36, Batch 1400] loss: 1.262\n",
      "[Epoch 37, Batch 100] loss: 1.246\n",
      "[Epoch 37, Batch 200] loss: 1.259\n",
      "[Epoch 37, Batch 300] loss: 1.259\n",
      "[Epoch 37, Batch 400] loss: 1.265\n",
      "[Epoch 37, Batch 500] loss: 1.257\n",
      "[Epoch 37, Batch 600] loss: 1.253\n",
      "[Epoch 37, Batch 700] loss: 1.257\n",
      "[Epoch 37, Batch 800] loss: 1.260\n",
      "[Epoch 37, Batch 900] loss: 1.271\n",
      "[Epoch 37, Batch 1000] loss: 1.254\n",
      "[Epoch 37, Batch 1100] loss: 1.254\n",
      "[Epoch 37, Batch 1200] loss: 1.248\n",
      "[Epoch 37, Batch 1300] loss: 1.260\n",
      "[Epoch 37, Batch 1400] loss: 1.260\n",
      "[Epoch 38, Batch 100] loss: 1.248\n",
      "[Epoch 38, Batch 200] loss: 1.259\n",
      "[Epoch 38, Batch 300] loss: 1.256\n",
      "[Epoch 38, Batch 400] loss: 1.255\n",
      "[Epoch 38, Batch 500] loss: 1.255\n",
      "[Epoch 38, Batch 600] loss: 1.255\n",
      "[Epoch 38, Batch 700] loss: 1.252\n",
      "[Epoch 38, Batch 800] loss: 1.256\n",
      "[Epoch 38, Batch 900] loss: 1.256\n",
      "[Epoch 38, Batch 1000] loss: 1.258\n",
      "[Epoch 38, Batch 1100] loss: 1.262\n",
      "[Epoch 38, Batch 1200] loss: 1.250\n",
      "[Epoch 38, Batch 1300] loss: 1.262\n",
      "[Epoch 38, Batch 1400] loss: 1.263\n",
      "[Epoch 39, Batch 100] loss: 1.261\n",
      "[Epoch 39, Batch 200] loss: 1.248\n",
      "[Epoch 39, Batch 300] loss: 1.258\n",
      "[Epoch 39, Batch 400] loss: 1.260\n",
      "[Epoch 39, Batch 500] loss: 1.252\n",
      "[Epoch 39, Batch 600] loss: 1.242\n",
      "[Epoch 39, Batch 700] loss: 1.256\n",
      "[Epoch 39, Batch 800] loss: 1.259\n",
      "[Epoch 39, Batch 900] loss: 1.259\n",
      "[Epoch 39, Batch 1000] loss: 1.259\n",
      "[Epoch 39, Batch 1100] loss: 1.258\n",
      "[Epoch 39, Batch 1200] loss: 1.256\n",
      "[Epoch 39, Batch 1300] loss: 1.258\n",
      "[Epoch 39, Batch 1400] loss: 1.258\n",
      "[Epoch 40, Batch 100] loss: 1.254\n",
      "[Epoch 40, Batch 200] loss: 1.255\n",
      "[Epoch 40, Batch 300] loss: 1.244\n",
      "[Epoch 40, Batch 400] loss: 1.254\n",
      "[Epoch 40, Batch 500] loss: 1.262\n",
      "[Epoch 40, Batch 600] loss: 1.255\n",
      "[Epoch 40, Batch 700] loss: 1.256\n",
      "[Epoch 40, Batch 800] loss: 1.261\n",
      "[Epoch 40, Batch 900] loss: 1.250\n",
      "[Epoch 40, Batch 1000] loss: 1.259\n",
      "[Epoch 40, Batch 1100] loss: 1.253\n",
      "[Epoch 40, Batch 1200] loss: 1.260\n",
      "[Epoch 40, Batch 1300] loss: 1.267\n",
      "[Epoch 40, Batch 1400] loss: 1.251\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# ÏÜêÏã§ Ìï®ÏàòÏôÄ ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï†ïÏùò\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.03)\n",
    "\n",
    "# Î™®Îç∏ ÌïôÏäµÏùÄ ÏßÅÏ†ë ÏûëÏÑ±Ìï¥Î≥¥ÏÑ∏Ïöî!!!\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ÏÜêÏã§ Ï∂úÎ†•\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Îß§ 100 ÎØ∏ÎãàÎ∞∞ÏπòÎßàÎã§ Ï∂úÎ†•\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "425ff1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îç∏ Ï∂úÎ†•: tensor([[4.7511e-03, 9.8163e-07, 2.3922e-06, 2.0287e-06, 9.9524e-01]])\n",
      "ÌôïÎ•†Ïù¥ Í∞ÄÏû• ÎÜíÏùÄ Î≥ÑÏ†ê: 5\n",
      "Í∏∞ÎåìÍ∞í: 4.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wkjeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "text = \"It's great, but there is some bugs\"\n",
    "\n",
    "def predict_review(model, review):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tensor_review = torch.tensor(text_pipeline(text))\n",
    "        output = model(tensor_review.reshape(-1, max_size))\n",
    "        print(f'Î™®Îç∏ Ï∂úÎ†•: {output}')\n",
    "        print(f'ÌôïÎ•†Ïù¥ Í∞ÄÏû• ÎÜíÏùÄ Î≥ÑÏ†ê: {output.argmax() + 1}')\n",
    "        print(f'Í∏∞ÎåìÍ∞í: {round(np.sum(np.array([1, 2, 3, 4, 5]) * output.detach().numpy()), 2)}')\n",
    "\n",
    "predict_review(model, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f96a67",
   "metadata": {},
   "source": [
    "# 5. NLP Ïù¥Ïö©Ìï¥Î≥¥Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb2ddf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (3.7)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "     ------------------------------------- 626.3/626.3 kB 13.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gensim in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 24.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wkjeo\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Installing collected packages: nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "Successfully installed nltk-3.9.1 textblob-0.18.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk textblob gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf9bc491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨, ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "\n",
    "#ÌÜ†ÌîΩÎ™®Îç∏ÎßÅ\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "658be1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>only problem is that we cant search year wise ...</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant cast to chromecast unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazing</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117640</th>\n",
       "      <td>i really like it there are so many movies and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117641</th>\n",
       "      <td>i love netflix i always enjoy my time using it</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117642</th>\n",
       "      <td>sound quality is very slow of movies</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117643</th>\n",
       "      <td>rate is very expensive bcos we see netflix sun...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117644</th>\n",
       "      <td>this app is awesome for english movies series ...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117645 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  score  \\\n",
       "0                                                      ok      5   \n",
       "1       only problem is that we cant search year wise ...      3   \n",
       "2                                                    good      5   \n",
       "3                    cant cast to chromecast unacceptable      1   \n",
       "4                                                 amazing      5   \n",
       "...                                                   ...    ...   \n",
       "117640  i really like it there are so many movies and ...      5   \n",
       "117641     i love netflix i always enjoy my time using it      5   \n",
       "117642               sound quality is very slow of movies      1   \n",
       "117643  rate is very expensive bcos we see netflix sun...      1   \n",
       "117644  this app is awesome for english movies series ...      4   \n",
       "\n",
       "       sentiment_label  \n",
       "0             positive  \n",
       "1             positive  \n",
       "2             positive  \n",
       "3              neutral  \n",
       "4             positive  \n",
       "...                ...  \n",
       "117640        positive  \n",
       "117641        positive  \n",
       "117642         neutral  \n",
       "117643        negative  \n",
       "117644        positive  \n",
       "\n",
       "[117645 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Í∞êÏÑ± Î∂ÑÏÑù\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['sentiment']=df['content'].apply(get_sentiment)\n",
    "df['sentiment_label'] = df['sentiment'].apply(lambda x:'positive' if x>0.1 else ('negative' if x<-0.1 else 'neutral'))\n",
    "df[['content','score','sentiment_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fdeef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5069e-03, 9.6764e-07, 2.3586e-06, 2.0025e-06, 9.9549e-01]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This app is great but has some bugs.\"\n",
    "\n",
    "tensor_review = torch.tensor(text_pipeline(text))\n",
    "output = model(tensor_review.reshape(-1, max_size))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9644e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
